{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import jsonschema, asyncio, types, fnmatch, urllib, dataclasses, builtins, collections, networkx, pathlib, IPython, \\\n",
    "    inspect, ujson as json, io, time, mimetypes, pyld, nbformat, aiofiles, aiohttp, collections, functools, typing, sys, rdflib.extras.external_graph_libs\n",
    "    from toolz.curried import *\n",
    "    mime = compose(first, mimetypes.guess_type, str)\n",
    "    Path = type(pathlib.Path(''))\n",
    "    IPython.display.HTML(\"\"\"<style>#notebook-container, .container {width: 100%;}</style>\"\"\")\n",
    "    \n",
    "    string_like = collections.UserString, rdflib.Namespace, rdflib.URIRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Composition(networkx.DiGraph):\n",
    "        triples = rdflib.ConjunctiveGraph()\n",
    "        sessions = {}\n",
    "        def weight(self, object, source, target, kwargs):\n",
    "            if source == type(object): \n",
    "                if isinstance(target, Validate): return 1/len(target) if target.validate(object) else 100000\n",
    "            if isinstance(target, types.FunctionType): return kwargs.get('weight', 500)\n",
    "            return kwargs.get('weight', 100)\n",
    "        \n",
    "        async def next(self, target, object): return networkx.shortest_path(self, type(object), target, weight=curry(self.weight)(object))\n",
    "        \n",
    "        async def advance(self, *targets, object, composition):\n",
    "            for target in targets:\n",
    "                callable, target = target, target.func if isinstance(target, functools.partial) else target\n",
    "\n",
    "                if target not in self: object = target(object); continue\n",
    "                    \n",
    "                try: source, next, *_ = await self.next(target, object)\n",
    "                except ValueError: continue\n",
    "                composition.add_edge(source, next)\n",
    "                if next in {None, builtins.object}: continue\n",
    "                if isinstance(next, types.ModuleType): continue\n",
    "                    \n",
    "                if next == target: next = callable \n",
    "                    \n",
    "                object = next() if object is None else next(object)  \n",
    "                if isinstance(object, types.FunctionType): object = object()                    \n",
    "                if inspect.isawaitable(object): object = await object\n",
    "                    \n",
    "                if next == target: \n",
    "                    self.compositions.add_edge(composition, target, object=object)\n",
    "                    continue\n",
    "                elif isinstance(target, type):\n",
    "                    if isinstance(type(object), target): \n",
    "                        self.compositions.add_edge(composition, target, object=object)\n",
    "                        continue\n",
    "                else:\n",
    "                    try:\n",
    "                        if object == target: \n",
    "                            self.compositions.add_edge(composition, target, object=object)\n",
    "                            continue\n",
    "                    except ValueError: ...\n",
    "                        \n",
    "                object = await self.advance(target, object=object, composition=composition)\n",
    "            return object\n",
    "        \n",
    "        async def text(self, path, attr='text', **kwargs):\n",
    "            if isinstance(path, pathlib.Path):\n",
    "                async with aiofiles.open(path, mode='r') as file: return await file.read()\n",
    "            async with self.sessions[aiohttp].get(str(path), **kwargs) as response: return await response.text()\n",
    "\n",
    "        async def rdf(self, path, format='nt', **kwargs): \n",
    "            graph = rdflib.Graph(store=self.triples.store, identifier=path)\n",
    "            graph.parse(str(path), format=format)\n",
    "            return graph\n",
    "\n",
    "        async def json(self, path, attr='text', **kwargs):\n",
    "            if isinstance(path, pathlib.Path):\n",
    "                async with aiofiles.open(path, mode='r') as file: return json.loads(await file.read())\n",
    "            async with self.sessions[aiohttp].get(str(path), **kwargs) as response: \n",
    "                try: return await response.json(content_type=None)\n",
    "                except BaseException as Exception: return Exception\n",
    "        \n",
    "        async def __call__(self, target, *object, keys=False, **data, ):\n",
    "            global sessions\n",
    "            key, value, compositions, originals = [], [], [], []\n",
    "            if not object: object = None,\n",
    "            if not isiterable(target): target = target,\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                self.sessions[aiohttp] = session\n",
    "                for object in object:\n",
    "                    originals.append(object)\n",
    "                    object = self.prepare(object)\n",
    "                    compositions.append(Composition())\n",
    "                    value.append(self.advance(*target, object=object, composition=compositions[-1]))\n",
    "                    try: self.compositions.add_edge(object, compositions[-1])\n",
    "                    except TypeError: ...\n",
    "                value = await asyncio.gather(*value)\n",
    "            try: \n",
    "                if keys: return dict(zip(originals, value))\n",
    "            except TypeError: ...\n",
    "            return value\n",
    "        \n",
    "        \n",
    "        def __add__(self, object, *types): \n",
    "            self.add_path([Forward[object] if isinstance(object, str) else object for object in object])\n",
    "            return self\n",
    "\n",
    "        @staticmethod\n",
    "        def prepare(object):\n",
    "            if isinstance(object, str):\n",
    "                original = str\n",
    "                if urllib.parse.urlparse(object).scheme in {'http', 'https'}: object = rdflib.Namespace(object)\n",
    "                else:\n",
    "                    try: \n",
    "                        path = pathlib.Path(object)\n",
    "                        if path.exists(): object = path\n",
    "                        else: object = collections.UserString(object)\n",
    "                    except:\n",
    "                        forward = Forward[object]\n",
    "                        if forward: object = forward\n",
    "            return object\n",
    "\n",
    "    Composition.compositions = Composition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def yaml(object):\n",
    "        try: import yaml\n",
    "        except: from ruamel import yaml\n",
    "        return yaml.safe_load(__import__('io').StringIO(str(object)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def new(cls, *args, _root=False): return type.__new__(cls, *args)\n",
    "    typing.TypingMeta.__new__ = new\n",
    "    def __getitem__(cls, object): return cls(object)\n",
    "    typing.TypingMeta.__getitem__ = __getitem__\n",
    "\n",
    "\n",
    "    class ForwardRef(getattr(typing, 'ForwardRef', getattr(typing, '_ForwardRef'))):\n",
    "        def __bool__(self): \n",
    "            try: self()\n",
    "            except: ...\n",
    "            return self.__forward_evaluated__\n",
    "        \n",
    "        def __call__(self, *object, globals=sys.modules, locals=sys.modules):\n",
    "            if self.__forward_evaluated__: \n",
    "                if callable(self.__forward_value__):\n",
    "                    if object: return self.__forward_value__(*object)\n",
    "                    else: return self.__forward_value__\n",
    "                return self.__forward_value__\n",
    "            try:\n",
    "                self.__forward_value__, self.__forward_evaluated__ = eval(self.__forward_arg__, globals, locals), True\n",
    "                return self(*object, globals=globals, locals=locals)\n",
    "            except: ...\n",
    "\n",
    "        def __hash__(self): \n",
    "            self()\n",
    "            try: return hash(self.__forward_value__ if self.__forward_evaluated__ else self.__forward_arg__)\n",
    "            except: return hash(self.__forward_arg__)\n",
    "                \n",
    "        def __eq__(self, object):\n",
    "            self();\n",
    "            try:\n",
    "                if hash(self) == hash(object): return True\n",
    "            except: \n",
    "                if self.__forward_arg__ == object: return True\n",
    "            return False\n",
    "        \n",
    "    Forward = ForwardRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @dataclasses.dataclass\n",
    "    class Validate:\n",
    "        data: object = ''\n",
    "        callable: callable = None\n",
    "        def __hash__(self): return hash(str(self.data))\n",
    "        def __len__(self): return len(self.data)\n",
    "        async def __call__(self, object): \n",
    "            if self.callable:\n",
    "                if isinstance(object, string_like): object = str(object)\n",
    "                object = self.callable(object) \n",
    "                if inspect.isawaitable(object): object = await object\n",
    "            return object\n",
    "        \n",
    "    class Mime(Validate, collections.UserString):\n",
    "        def validate(self, object): \n",
    "            if isinstance(object, type(self)): return hash(object) == hash(self)\n",
    "            return not self.data or self.data == mime(str(object))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Pattern(collections.UserList, Validate): \n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.callable = kwargs.pop('callable', None)\n",
    "            super().__init__(*args, **kwargs)\n",
    "        def validate(self, object): return any(fnmatch.fnmatch(str(object), pattern) for pattern in self.data)\n",
    "        def __hash__(self): return hash(tuple(self.data))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Schema(jsonschema.Draft4Validator, Validate):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.callable = kwargs.pop('callable', None)\n",
    "            super().__init__(*args, **kwargs)\n",
    "            \n",
    "        @property\n",
    "        def data(self): return self.schema\n",
    "        def validate(self, object):\n",
    "            try: return super().validate(object) or True\n",
    "            except jsonschema.ValidationError: return False\n",
    "        \n",
    "        @classmethod\n",
    "        def new(cls, type, **kwargs):\n",
    "            class Model(__import__('pydantic').BaseModel): object: type\n",
    "            schema = json.loads(Model.schema_json())['properties']['object']\n",
    "            return cls(schema.pop('title') and schema, **kwargs)\n",
    "        \n",
    "        def __len__(self): return len(pyld.jsonld.compact({'@context': {'@vocab': '://',\n",
    "                                     'definitions': '@nest', 'properties': '@nest'\n",
    "                                     }, **nbformat.validator._get_schema_json(nbformat.v4)}, {'@vocab': '://'}).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def series_to_frame(series):\n",
    "        if series.dtypes == __import__('pandas').np.dtype('O'): return series.apply(__import__('pandas').Series)\n",
    "        return series.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    mimetypes.add_type('text/markdown', '.md')\n",
    "    mimetypes.add_type('text/markdown', '.markdown')\n",
    "    mimetypes.add_type('application/x-sqlite3', '.sqlite')\n",
    "    mimetypes.add_type('application/x-yaml', '.yml')\n",
    "    mimetypes.add_type('application/x-yaml', '.yaml')\n",
    "    mimetypes.add_type('application/x-ipynb+json', '.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @curry\n",
    "    def convert(type, nb): \n",
    "        for cell in nb.cells: cell.source = ''.join(cell.source)\n",
    "        return __import__('nbconvert').get_exporter(type)().from_notebook_node(nb)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Composition at 0x151605bb70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    ado = Composition()\n",
    "    JSON = Mime('application/json', callable=ado.json)\n",
    "    ado + [Composition, networkx.to_directed, networkx.DiGraph]\n",
    "    ado + [rdflib.Namespace, compose(partial(\n",
    "        IPython.display.IFrame, width='100%', height='600px'\n",
    "    ),str), IPython.display.IFrame]\n",
    "    \n",
    "    ado + [rdflib.Namespace, ado.json, dict] + [ado.json, list] + [ado.json, float] + [ado.json, int]\n",
    "    ado + [rdflib.Namespace, ado.text, str]\n",
    "    \n",
    "    ado + [Path, Mime('text/html', callable=compose(IPython.display.HTML, str)), IPython.display.HTML]\n",
    "    ado + [Path, Mime('text/markdown', callable=compose(IPython.display.Markdown, str)), IPython.display.Markdown]\n",
    "    ado + [Path, Mime('application/json', callable=compose(IPython.display.JSON, str)), IPython.display.JSON]   \n",
    "    \n",
    "    ado + [Path, Mime('application/x-yaml', callable=ado.text), str, yaml] \n",
    "    ado + [collections.UserString, yaml] + [yaml, dict, IPython.display.JSON] + [yaml, list, IPython.display.JSON] + [yaml, float] + [yaml, int] \n",
    "    ado + [yaml, type(None)] + [yaml, str]\n",
    "    ado + [Path, JSON, dict] + [JSON, list] + [JSON, float] + [JSON, int]\n",
    "    ado + [Mime('application/json', callable=ado.text), str]\n",
    "        \n",
    "    \n",
    "    ado + [Path, Mime('text/csv', callable=Forward['pandas.read_csv']), 'pandas.DataFrame']\n",
    "    ado + [rdflib.Namespace, Mime('text/csv', callable=Forward['pandas.read_csv']), 'pandas.DataFrame']\n",
    "    ado + [list, Schema.new(typing.List[typing.Union[int, None, float, str]], callable=Forward['pandas.Series']), 'pandas.Series']\n",
    "    ado + ['pandas.Series', series_to_frame, 'pandas.DataFrame']\n",
    "    \n",
    "    ado + [list, Schema.new(typing.List[typing.Union[list, dict]], callable=Forward['pandas.DataFrame']), 'pandas.DataFrame', 'pandas.DataFrame.transpose']\n",
    "    ado + [dict, 'pandas.Series']\n",
    "    \n",
    "    ado + [Path, Mime('application/x-ipynb+json', callable=ado.json), dict, 'nbformat.from_dict', 'nbformat.NotebookNode']\n",
    "    ado + ['nbformat.NotebookNode', convert('html'), str, IPython.display.HTML]\n",
    "    \n",
    "    ado + [Path, Mime('image/png', callable=compose(IPython.display.Image, str)), IPython.display.Image]\n",
    "    ado + [Path, Mime('image/jpeg', callable=compose(IPython.display.Image, str)), IPython.display.Image]  \n",
    "    ado + [Path, Mime('image/bmp', callable=compose(IPython.display.Image, str)), IPython.display.Image]\n",
    "    ado + [Path, Mime('image/svg+xml', callable=compose(IPython.display.SVG, str)), IPython.display.SVG]   \n",
    "    \n",
    "    ado + [Path, Mime('image/png', callable=Forward('skimage.io.imread')), 'pandas.np.ndarray']\n",
    "    ado + [Path, Mime('image/jpeg', callable=Forward('skimage.io.imread')), 'pandas.np.ndarray']\n",
    "    ado + [Path, Mime('image/bmp', callable=Forward('skimage.io.imread')), 'pandas.np.ndarray', list]\n",
    "\n",
    "    ado + [rdflib.Namespace, Mime('image/png', callable=Forward('skimage.io.imread')), 'pandas.np.ndarray']\n",
    "    ado + [rdflib.Namespace, Mime('image/jpeg', callable=Forward('skimage.io.imread')), 'pandas.np.ndarray']\n",
    "    ado + [rdflib.Namespace, Mime('image/bmp', callable=Forward('skimage.io.imread')), 'pandas.np.ndarray', list]\n",
    "\n",
    "    \n",
    "    ado + [dict, Schema.new(typing.Dict[str, list], callable=partial(networkx.from_dict_of_lists, create_using=networkx.DiGraph)), networkx.DiGraph]\n",
    "    ado + [dict, Schema.new(typing.Dict[str, dict], callable=partial(networkx.from_dict_of_dicts, create_using=networkx.DiGraph)), networkx.DiGraph]\n",
    "    ado + [dict, Schema.new(typing.Dict[str, list], callable=networkx.from_dict_of_lists), networkx.Graph]\n",
    "    ado + [dict, Schema.new(typing.Dict[str, dict], callable=networkx.from_dict_of_dicts), networkx.Graph]\n",
    "    \n",
    "    [ado + [object, IPython.display.display] for object in list(ado.node) if isinstance(object, type) and issubclass(object, IPython.display.DisplayObject)]\n",
    "    ado + [networkx.DiGraph, networkx.nx_pydot.to_pydot] + [networkx.Graph, networkx.nx_pydot.to_pydot, 'pydot.Dot', 'graphviz.Source']\n",
    "\n",
    "    ado + [Forward, operator.attrgetter('__forward_value__'), dict]\n",
    "    ado + [Forward, operator.attrgetter('__forward_value__'), list]\n",
    "    ado + [type(None), 'pandas.util.testing.makeDataFrame', 'pandas.DataFrame']\n",
    "    \n",
    "    ado + [rdflib.Namespace, ado.rdf, rdflib.Graph, rdflib.extras.external_graph_libs.rdflib_to_networkx_digraph, networkx.DiGraph]\n",
    "    ado + [rdflib.Graph, rdflib.extras.external_graph_libs.rdflib_to_networkx_graph, networkx.Graph]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
